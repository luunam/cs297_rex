{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Submarket baseline\n\nSteps include:\n\n1. kmeans to find submarkets\n2. Fit logistic regressions on the submarkets\n3. Compare accuracy scores against other submarket & non-submarket approaches",
      "metadata": {
        "tags": [],
        "cell_id": "00000-944ec318-1792-47a6-bccb-30f4e9e21dce",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 6020,
        "source_hash": "e9d36ba5",
        "tags": [],
        "cell_id": "00001-090243ac-3be1-44b4-b2ca-1257aecc84a2",
        "execution_start": 1619565255822,
        "deepnote_cell_type": "code"
      },
      "source": "#required packages\nimport sys\nsys.path.insert(0, '../scripts/')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as T\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pymc3 as pm\nimport chardet\nimport datetime\n\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n\nfrom models import AE, BaselineNet\n\nfrom utils import *",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "text": "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 884,
        "source_hash": "41106579",
        "tags": [],
        "cell_id": "00002-aea52d55-74fb-452b-a6bd-15f22b8bebd1",
        "execution_start": 1619565261854,
        "deepnote_cell_type": "code"
      },
      "source": "# Load dataset\ndf = pd.read_csv('../data/denver_dataset_milestone3.csv', index_col=0)\n\n#convert to datetime format\ndf[\"list_date\"] = pd.to_datetime(df[\"list_date\"])\ndf[\"sale_date\"] = pd.to_datetime(df[\"sale_date\"])\n\ndf = df.drop(columns=['rex_property_id'])\ndf = df.dropna()\nres = gen_dataset(df, '2019-04-01', 90)",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'bool': ['OTHER', 'CONDO', 'MULTI_FAMILY'], 'int64': ['mean_household_income', 'farm_score', 'bathfull', 'bedrooms'], 'float64': ['18-59', 'built 1995 or later', 'mobile_home_pct', 'annual_births_per_resident', 'luxury_communities_score', 'property_crime_rate', 'small_apt_buildings_pct', 'standardized_test_score_percentile', 'latitude', 'longitude'], 'datetime64[ns]': ['list_date', 'sale_date']}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-fa7f2f85-0315-430e-a10c-13eafab65a32",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2f52102c",
        "execution_start": 1619565262715,
        "execution_millis": 9,
        "deepnote_cell_type": "code"
      },
      "source": "X = res['X']\nY = res['y']\n\nX_lat = X.copy()\nX = X.drop(columns=['latitude', 'longitude'])",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00007-a455311e-df97-4d2a-b585-28101d93da26",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7abc5eab",
        "execution_millis": 3,
        "execution_start": 1619565262724,
        "deepnote_cell_type": "code"
      },
      "source": "def print_results(model,thresh=0.5):\n  print('Train set accuracy: {}'.format(accuracy_score(y_train, np.where(pred_k_train[:,1]>thresh,1,0))))\n  print('Test set accuracy: {}'.format(accuracy_score(y_test, np.where(pred_k[:,1]>thresh,1,0))))\n\n  return accuracy_score(y_train, np.where(pred_k_train[:,1]>thresh,1,0)), accuracy_score(y_test, np.where(pred_k[:,1]>thresh,1,0))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 79952,
        "source_hash": "755190c1",
        "tags": [],
        "cell_id": "00006-5aead42b-65c5-4a2b-85ff-cea81aec1acf",
        "execution_start": 1619565262743,
        "deepnote_cell_type": "code"
      },
      "source": "#attempt kmeans clustering\n#unsupervised approach\n#finding the optimum value of k\n\nmse_list = []\n\nfor clus_num in range(3,20,1):\n    K = clus_num\n    init_clustering = KMeans(n_clusters=K, random_state=0).fit(X_lat)\n\n    cluster_labels = init_clustering.labels_\n\n    for k in range(K):\n        print('Submarket {}: {} units'.format(k, sum(cluster_labels == k)))\n\n    #create a new df with has the clustering labels on it\n    X_withlabels = X.copy()\n    X_withlabels['labels'] = cluster_labels \n\n    # Fitting logistic regression to identified clusters from Kmeans\n    train_test_dict = {}\n\n    #for loop which extracts the X & y df for each cluster\n    #these will then be used to run the logistic regression \n    for i in range(K):\n        X2 = X_withlabels.loc[X_withlabels['labels'] == i]\n        X2 = X2.drop(columns = 'labels')\n        y2 = Y[X_withlabels['labels'] == i]\n        X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.33, random_state =297)\n\n        train_test_dict[f'cluster {i}'] = (X_train, X_test, y_train, y_test)\n\n    #now to fit for each cluster and get final results\n\n    \n\n    train_acc_agg = 0\n    train_size = 0\n    test_acc_agg = 0\n    test_expsales_agg = 0\n    test_sales_agg = 0\n    test_size = 0\n\n    test = np.array([])\n    pred = np.array([])\n\n    #fit k number of logistic regressions and get results\n    for i in range(K):\n        logit_reg = LogisticRegression()\n        X_train = train_test_dict[f'cluster {i}'][0]\n        X_test = train_test_dict[f'cluster {i}'][1]\n        y_train = train_test_dict[f'cluster {i}'][2]\n        y_test = train_test_dict[f'cluster {i}'][3]\n\n        #fit the logistic regression to each cluster\n        logit_reg.fit(X_train, y_train)\n\n            #the below code is used in order to create a df containing a breakdown of metrics\n    #on a per cluster basis\n        print(f'For cluster {i}')\n        pred_k_train = logit_reg.predict_proba(X_train)\n        pred_k = logit_reg.predict_proba(X_test)\n\n        train_accuracy, test_accuracy = print_results(logit_reg)\n        exp_sales = sum(logit_reg.predict_proba(X_test)[:,1])\n        actual_sales = sum(y_test)\n    \n        print(\"Number of Homes: {}\".format(len(y_test)))\n        print(\"Expected #Sales: {}\".format(round(exp_sales)))\n        print(\"Actual #Sales: {}\\n\".format(actual_sales))\n        print('=======')\n\n        \n        #the below code is used to find the weighted average\n        test = np.append(test,y_test)\n        pred = np.append(pred,pred_k[:,1])\n        train_size += len(y_train)\n        train_acc_agg += train_accuracy * len(y_train)\n        test_size += len(y_test)\n        test_acc_agg += test_accuracy * len(y_test)\n        test_expsales_agg += round(exp_sales)\n        test_sales_agg += actual_sales\n\n    #find MSE for this k value and append to list\n    #we will choose the submarket with the lowest MSE\n    mse_list.append(mean_squared_error([test_expsales_agg],[test_sales_agg]))\n    \n",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "text": "Expected #Sales: 665\nActual #Sales: 645\n\n=======\nFor cluster 2\nTrain set accuracy: 0.7692307692307693\nTest set accuracy: 0.7464788732394366\nNumber of Homes: 71\nExpected #Sales: 16\nActual #Sales: 18\n\n=======\nFor cluster 3\nTrain set accuracy: 0.6455696202531646\nTest set accuracy: 0.6741071428571429\nNumber of Homes: 896\nExpected #Sales: 317\nActual #Sales: 292\n\n=======\nFor cluster 4\nTrain set accuracy: 0.5845661735305878\nTest set accuracy: 0.5644768856447688\nNumber of Homes: 1233\nExpected #Sales: 512\nActual #Sales: 537\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6974358974358974\nTest set accuracy: 0.7508650519031141\nNumber of Homes: 289\nExpected #Sales: 87\nActual #Sales: 72\n\n=======\nFor cluster 6\nTrain set accuracy: 0.64037558685446\nTest set accuracy: 0.625158831003812\nNumber of Homes: 1574\nExpected #Sales: 564\nActual #Sales: 591\n\n=======\nFor cluster 7\nTrain set accuracy: 0.6409618573797679\nTest set accuracy: 0.6156433978132885\nNumber of Homes: 1189\nExpected #Sales: 425\nActual #Sales: 457\n\n=======\nFor cluster 8\nTrain set accuracy: 0.6328125\nTest set accuracy: 0.6875\nNumber of Homes: 64\nExpected #Sales: 24\nActual #Sales: 20\n\n=======\nFor cluster 9\nTrain set accuracy: 0.6801426872770512\nTest set accuracy: 0.6887816646562123\nNumber of Homes: 829\nExpected #Sales: 266\nActual #Sales: 258\n\n=======\nFor cluster 10\nTrain set accuracy: 0.5668067226890756\nTest set accuracy: 0.6214833759590793\nNumber of Homes: 1173\nExpected #Sales: 510\nActual #Sales: 444\n\n=======\nFor cluster 11\nTrain set accuracy: 0.6215062111801242\nTest set accuracy: 0.6440944881889764\nNumber of Homes: 1270\nExpected #Sales: 479\nActual #Sales: 451\n\n=======\nFor cluster 12\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nSubmarket 0: 3734 units\nSubmarket 1: 2246 units\nSubmarket 2: 214 units\nSubmarket 3: 4769 units\nSubmarket 4: 498 units\nSubmarket 5: 5115 units\nSubmarket 6: 3553 units\nSubmarket 7: 657 units\nSubmarket 8: 2713 units\nSubmarket 9: 132 units\nSubmarket 10: 2010 units\nSubmarket 11: 1019 units\nSubmarket 12: 3846 units\nSubmarket 13: 3601 units\nFor cluster 0\nTrain set accuracy: 0.5845661735305878\nTest set accuracy: 0.5644768856447688\nNumber of Homes: 1233\nExpected #Sales: 512\nActual #Sales: 537\n\n=======\nFor cluster 1\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nFor cluster 2\nTrain set accuracy: 0.7692307692307693\nTest set accuracy: 0.7464788732394366\nNumber of Homes: 71\nExpected #Sales: 16\nActual #Sales: 18\n\n=======\nFor cluster 3\nTrain set accuracy: 0.64037558685446\nTest set accuracy: 0.625158831003812\nNumber of Homes: 1574\nExpected #Sales: 564\nActual #Sales: 591\n\n=======\nFor cluster 4\nTrain set accuracy: 0.6996996996996997\nTest set accuracy: 0.7515151515151515\nNumber of Homes: 165\nExpected #Sales: 50\nActual #Sales: 41\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6069448497227896\nTest set accuracy: 0.6178909952606635\nNumber of Homes: 1688\nExpected #Sales: 665\nActual #Sales: 645\n\n=======\nFor cluster 6\nTrain set accuracy: 0.5668067226890756\nTest set accuracy: 0.6214833759590793\nNumber of Homes: 1173\nExpected #Sales: 510\nActual #Sales: 444\n\n=======\nFor cluster 7\nTrain set accuracy: 0.7227272727272728\nTest set accuracy: 0.6728110599078341\nNumber of Homes: 217\nExpected #Sales: 61\nActual #Sales: 71\n\n=======\nFor cluster 8\nTrain set accuracy: 0.6455696202531646\nTest set accuracy: 0.6741071428571429\nNumber of Homes: 896\nExpected #Sales: 317\nActual #Sales: 292\n\n=======\nFor cluster 9\nTrain set accuracy: 0.7045454545454546\nTest set accuracy: 0.5909090909090909\nNumber of Homes: 44\nExpected #Sales: 13\nActual #Sales: 18\n\n=======\nFor cluster 10\nTrain set accuracy: 0.6894502228826151\nTest set accuracy: 0.6807228915662651\nNumber of Homes: 664\nExpected #Sales: 206\nActual #Sales: 212\n\n=======\nFor cluster 11\nTrain set accuracy: 0.658357771260997\nTest set accuracy: 0.6824925816023739\nNumber of Homes: 337\nExpected #Sales: 115\nActual #Sales: 107\n\n=======\nFor cluster 12\nTrain set accuracy: 0.6215062111801242\nTest set accuracy: 0.6440944881889764\nNumber of Homes: 1270\nExpected #Sales: 479\nActual #Sales: 451\n\n=======\nFor cluster 13\nTrain set accuracy: 0.6409618573797679\nTest set accuracy: 0.6156433978132885\nNumber of Homes: 1189\nExpected #Sales: 425\nActual #Sales: 457\n\n=======\nSubmarket 0: 2989 units\nSubmarket 1: 1019 units\nSubmarket 2: 3601 units\nSubmarket 3: 214 units\nSubmarket 4: 2373 units\nSubmarket 5: 3709 units\nSubmarket 6: 554 units\nSubmarket 7: 192 units\nSubmarket 8: 3323 units\nSubmarket 9: 2246 units\nSubmarket 10: 4855 units\nSubmarket 11: 2928 units\nSubmarket 12: 2010 units\nSubmarket 13: 541 units\nSubmarket 14: 3553 units\nFor cluster 0\nTrain set accuracy: 0.6323676323676324\nTest set accuracy: 0.6494427558257345\nNumber of Homes: 987\nExpected #Sales: 360\nActual #Sales: 343\n\n=======\nFor cluster 1\nTrain set accuracy: 0.658357771260997\nTest set accuracy: 0.6824925816023739\nNumber of Homes: 337\nExpected #Sales: 115\nActual #Sales: 107\n\n=======\nFor cluster 2\nTrain set accuracy: 0.6409618573797679\nTest set accuracy: 0.6156433978132885\nNumber of Homes: 1189\nExpected #Sales: 425\nActual #Sales: 457\n\n=======\nFor cluster 3\nTrain set accuracy: 0.7692307692307693\nTest set accuracy: 0.7464788732394366\nNumber of Homes: 71\nExpected #Sales: 16\nActual #Sales: 18\n\n=======\nFor cluster 4\nTrain set accuracy: 0.6601636249213342\nTest set accuracy: 0.6568877551020408\nNumber of Homes: 784\nExpected #Sales: 268\nActual #Sales: 269\n\n=======\nFor cluster 5\nTrain set accuracy: 0.586317907444668\nTest set accuracy: 0.5629084967320261\nNumber of Homes: 1224\nExpected #Sales: 506\nActual #Sales: 535\n\n=======\nFor cluster 6\nTrain set accuracy: 0.706199460916442\nTest set accuracy: 0.726775956284153\nNumber of Homes: 183\nExpected #Sales: 54\nActual #Sales: 50\n\n=======\nFor cluster 7\nTrain set accuracy: 0.6328125\nTest set accuracy: 0.6875\nNumber of Homes: 64\nExpected #Sales: 24\nActual #Sales: 20\n\n=======\nFor cluster 8\nTrain set accuracy: 0.62848158131177\nTest set accuracy: 0.6253418413855971\nNumber of Homes: 1097\nExpected #Sales: 407\nActual #Sales: 411\n\n=======\nFor cluster 9\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nFor cluster 10\nTrain set accuracy: 0.6091635916359164\nTest set accuracy: 0.6051154086088584\nNumber of Homes: 1603\nExpected #Sales: 627\nActual #Sales: 633\n\n=======\nFor cluster 11\nTrain set accuracy: 0.6420193778684344\nTest set accuracy: 0.609100310237849\nNumber of Homes: 967\nExpected #Sales: 346\nActual #Sales: 378\n\n=======\nFor cluster 12\nTrain set accuracy: 0.6894502228826151\nTest set accuracy: 0.6807228915662651\nNumber of Homes: 664\nExpected #Sales: 206\nActual #Sales: 212\n\n=======\nFor cluster 13\nTrain set accuracy: 0.7154696132596685\nTest set accuracy: 0.7262569832402235\nNumber of Homes: 179\nExpected #Sales: 51\nActual #Sales: 49\n\n=======\nFor cluster 14\nTrain set accuracy: 0.5668067226890756\nTest set accuracy: 0.6214833759590793\nNumber of Homes: 1173\nExpected #Sales: 510\nActual #Sales: 444\n\n=======\nSubmarket 0: 525 units\nSubmarket 1: 4020 units\nSubmarket 2: 3784 units\nSubmarket 3: 2925 units\nSubmarket 4: 52 units\nSubmarket 5: 2511 units\nSubmarket 6: 4116 units\nSubmarket 7: 2687 units\nSubmarket 8: 4322 units\nSubmarket 9: 498 units\nSubmarket 10: 162 units\nSubmarket 11: 2246 units\nSubmarket 12: 132 units\nSubmarket 13: 650 units\nSubmarket 14: 3060 units\nSubmarket 15: 2417 units\nFor cluster 0\nTrain set accuracy: 0.6951566951566952\nTest set accuracy: 0.7241379310344828\nNumber of Homes: 174\nExpected #Sales: 54\nActual #Sales: 48\n\n=======\nFor cluster 1\nTrain set accuracy: 0.604158930560713\nTest set accuracy: 0.6292388847023361\nNumber of Homes: 1327\nExpected #Sales: 525\nActual #Sales: 492\n\n=======\nFor cluster 2\nTrain set accuracy: 0.6299802761341223\nTest set accuracy: 0.622097678142514\nNumber of Homes: 1249\nExpected #Sales: 464\nActual #Sales: 472\n\n=======\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\nFor cluster 3\nTrain set accuracy: 0.6370597243491577\nTest set accuracy: 0.6376811594202898\nNumber of Homes: 966\nExpected #Sales: 353\nActual #Sales: 338\n\n=======\nFor cluster 4\nTrain set accuracy: 0.6176470588235294\nTest set accuracy: 0.9444444444444444\nNumber of Homes: 18\nExpected #Sales: 7\nActual #Sales: 1\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6801426872770512\nTest set accuracy: 0.6887816646562123\nNumber of Homes: 829\nExpected #Sales: 266\nActual #Sales: 258\n\n=======\nFor cluster 6\nTrain set accuracy: 0.5770765324628219\nTest set accuracy: 0.5710080941869021\nNumber of Homes: 1359\nExpected #Sales: 575\nActual #Sales: 583\n\n=======\nFor cluster 7\nTrain set accuracy: 0.6466666666666666\nTest set accuracy: 0.6764374295377678\nNumber of Homes: 887\nExpected #Sales: 313\nActual #Sales: 287\n\n=======\nFor cluster 8\nTrain set accuracy: 0.6397236614853196\nTest set accuracy: 0.6250875963559915\nNumber of Homes: 1427\nExpected #Sales: 515\nActual #Sales: 535\n\n=======\nFor cluster 9\nTrain set accuracy: 0.6996996996996997\nTest set accuracy: 0.7515151515151515\nNumber of Homes: 165\nExpected #Sales: 50\nActual #Sales: 41\n\n=======\nFor cluster 10\nTrain set accuracy: 0.7870370370370371\nTest set accuracy: 0.7407407407407407\nNumber of Homes: 54\nExpected #Sales: 11\nActual #Sales: 14\n\n=======\nFor cluster 11\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nFor cluster 12\nTrain set accuracy: 0.7045454545454546\nTest set accuracy: 0.5909090909090909\nNumber of Homes: 44\nExpected #Sales: 13\nActual #Sales: 18\n\n=======\nFor cluster 13\nTrain set accuracy: 0.6758620689655173\nTest set accuracy: 0.6697674418604651\nNumber of Homes: 215\nExpected #Sales: 70\nActual #Sales: 71\n\n=======\nFor cluster 14\nTrain set accuracy: 0.5965853658536585\nTest set accuracy: 0.5900990099009901\nNumber of Homes: 1010\nExpected #Sales: 408\nActual #Sales: 414\n\n=======\nFor cluster 15\nTrain set accuracy: 0.5941939468807906\nTest set accuracy: 0.6190476190476191\nNumber of Homes: 798\nExpected #Sales: 324\nActual #Sales: 304\n\n=======\nSubmarket 0: 3519 units\nSubmarket 1: 2246 units\nSubmarket 2: 405 units\nSubmarket 3: 3231 units\nSubmarket 4: 162 units\nSubmarket 5: 3224 units\nSubmarket 6: 650 units\nSubmarket 7: 3438 units\nSubmarket 8: 132 units\nSubmarket 9: 2511 units\nSubmarket 10: 2906 units\nSubmarket 11: 618 units\nSubmarket 12: 2485 units\nSubmarket 13: 2704 units\nSubmarket 14: 2915 units\nSubmarket 15: 52 units\nSubmarket 16: 2909 units\nFor cluster 0\nTrain set accuracy: 0.6054306321595249\nTest set accuracy: 0.6135972461273667\nNumber of Homes: 1162\nExpected #Sales: 458\nActual #Sales: 449\n\n=======\nFor cluster 1\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nFor cluster 2\nTrain set accuracy: 0.7195571955719557\nTest set accuracy: 0.7686567164179104\nNumber of Homes: 134\nExpected #Sales: 40\nActual #Sales: 31\n\n=======\nFor cluster 3\nTrain set accuracy: 0.5951940850277264\nTest set accuracy: 0.5745079662605436\nNumber of Homes: 1067\nExpected #Sales: 433\nActual #Sales: 454\n\n=======\nFor cluster 4\nTrain set accuracy: 0.7870370370370371\nTest set accuracy: 0.7407407407407407\nNumber of Homes: 54\nExpected #Sales: 11\nActual #Sales: 14\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6342592592592593\nTest set accuracy: 0.6221804511278195\nNumber of Homes: 1064\nExpected #Sales: 389\nActual #Sales: 402\n\n=======\nFor cluster 6\nTrain set accuracy: 0.6758620689655173\nTest set accuracy: 0.6697674418604651\nNumber of Homes: 215\nExpected #Sales: 70\nActual #Sales: 71\n\n=======\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\nFor cluster 7\nTrain set accuracy: 0.6365610073816761\nTest set accuracy: 0.626431718061674\nNumber of Homes: 1135\nExpected #Sales: 411\nActual #Sales: 424\n\n=======\nFor cluster 8\nTrain set accuracy: 0.7045454545454546\nTest set accuracy: 0.5909090909090909\nNumber of Homes: 44\nExpected #Sales: 13\nActual #Sales: 18\n\n=======\nFor cluster 9\nTrain set accuracy: 0.6801426872770512\nTest set accuracy: 0.6887816646562123\nNumber of Homes: 829\nExpected #Sales: 266\nActual #Sales: 258\n\n=======\nFor cluster 10\nTrain set accuracy: 0.6014381099126862\nTest set accuracy: 0.5881126173096975\nNumber of Homes: 959\nExpected #Sales: 382\nActual #Sales: 395\n\n=======\nFor cluster 11\nTrain set accuracy: 0.6714975845410628\nTest set accuracy: 0.7401960784313726\nNumber of Homes: 204\nExpected #Sales: 68\nActual #Sales: 53\n\n=======\nFor cluster 12\nTrain set accuracy: 0.6496394230769231\nTest set accuracy: 0.679658952496955\nNumber of Homes: 821\nExpected #Sales: 288\nActual #Sales: 263\n\n=======\nFor cluster 13\nTrain set accuracy: 0.6311430149088901\nTest set accuracy: 0.6550951847704367\nNumber of Homes: 893\nExpected #Sales: 335\nActual #Sales: 301\n\n=======\nFor cluster 14\nTrain set accuracy: 0.6246799795186891\nTest set accuracy: 0.6288981288981289\nNumber of Homes: 962\nExpected #Sales: 359\nActual #Sales: 357\n\n=======\nFor cluster 15\nTrain set accuracy: 0.6176470588235294\nTest set accuracy: 0.9444444444444444\nNumber of Homes: 18\nExpected #Sales: 7\nActual #Sales: 1\n\n=======\nFor cluster 16\nTrain set accuracy: 0.5797845048742946\nTest set accuracy: 0.5770833333333333\nNumber of Homes: 960\nExpected #Sales: 404\nActual #Sales: 406\n\n=======\nSubmarket 0: 878 units\nSubmarket 1: 2928 units\nSubmarket 2: 438 units\nSubmarket 3: 3519 units\nSubmarket 4: 162 units\nSubmarket 5: 2010 units\nSubmarket 6: 2884 units\nSubmarket 7: 192 units\nSubmarket 8: 3323 units\nSubmarket 9: 657 units\nSubmarket 10: 2246 units\nSubmarket 11: 2749 units\nSubmarket 12: 1019 units\nSubmarket 13: 2704 units\nSubmarket 14: 3042 units\nSubmarket 15: 52 units\nSubmarket 16: 2373 units\nSubmarket 17: 2931 units\nFor cluster 0\nTrain set accuracy: 0.6292517006802721\nTest set accuracy: 0.6068965517241379\nNumber of Homes: 290\nExpected #Sales: 110\nActual #Sales: 113\n\n=======\nFor cluster 1\nTrain set accuracy: 0.6420193778684344\nTest set accuracy: 0.609100310237849\nNumber of Homes: 967\nExpected #Sales: 346\nActual #Sales: 378\n\n=======\nFor cluster 2\nTrain set accuracy: 0.7303754266211604\nTest set accuracy: 0.7310344827586207\nNumber of Homes: 145\nExpected #Sales: 38\nActual #Sales: 39\n\n=======\nFor cluster 3\nTrain set accuracy: 0.6054306321595249\nTest set accuracy: 0.6135972461273667\nNumber of Homes: 1162\nExpected #Sales: 458\nActual #Sales: 449\n\n=======\nFor cluster 4\nTrain set accuracy: 0.7870370370370371\nTest set accuracy: 0.7407407407407407\nNumber of Homes: 54\nExpected #Sales: 11\nActual #Sales: 14\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6894502228826151\nTest set accuracy: 0.6807228915662651\nNumber of Homes: 664\nExpected #Sales: 206\nActual #Sales: 212\n\n=======\nFor cluster 6\nTrain set accuracy: 0.5822981366459627\nTest set accuracy: 0.5672268907563025\nNumber of Homes: 952\nExpected #Sales: 398\nActual #Sales: 412\n\n=======\nFor cluster 7\nTrain set accuracy: 0.6328125\nTest set accuracy: 0.6875\nNumber of Homes: 64\nExpected #Sales: 24\nActual #Sales: 20\n\n=======\nFor cluster 8\nTrain set accuracy: 0.62848158131177\nTest set accuracy: 0.6253418413855971\nNumber of Homes: 1097\nExpected #Sales: 407\nActual #Sales: 411\n\n=======\nFor cluster 9\nTrain set accuracy: 0.7227272727272728\nTest set accuracy: 0.6728110599078341\nNumber of Homes: 217\nExpected #Sales: 61\nActual #Sales: 71\n\n=======\nFor cluster 10\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nFor cluster 11\nTrain set accuracy: 0.6360673546985334\nTest set accuracy: 0.6376651982378855\nNumber of Homes: 908\nExpected #Sales: 333\nActual #Sales: 329\n\n=======\nFor cluster 12\nTrain set accuracy: 0.658357771260997\nTest set accuracy: 0.6824925816023739\nNumber of Homes: 337\nExpected #Sales: 115\nActual #Sales: 107\n\n=======\nFor cluster 13\nTrain set accuracy: 0.6311430149088901\nTest set accuracy: 0.6550951847704367\nNumber of Homes: 893\nExpected #Sales: 335\nActual #Sales: 301\n\n=======\nFor cluster 14\nTrain set accuracy: 0.5961727183513248\nTest set accuracy: 0.5627490039840638\nNumber of Homes: 1004\nExpected #Sales: 406\nActual #Sales: 439\n\n=======\nFor cluster 15\nTrain set accuracy: 0.6176470588235294\nTest set accuracy: 0.9444444444444444\nNumber of Homes: 18\nExpected #Sales: 7\nActual #Sales: 1\n\n=======\nFor cluster 16\nTrain set accuracy: 0.6601636249213342\nTest set accuracy: 0.6568877551020408\nNumber of Homes: 784\nExpected #Sales: 268\nActual #Sales: 269\n\n=======\nFor cluster 17\nTrain set accuracy: 0.5909322465613857\nTest set accuracy: 0.6012396694214877\nNumber of Homes: 968\nExpected #Sales: 397\nActual #Sales: 377\n\n=======\nSubmarket 0: 2373 units\nSubmarket 1: 3044 units\nSubmarket 2: 132 units\nSubmarket 3: 3298 units\nSubmarket 4: 1019 units\nSubmarket 5: 3375 units\nSubmarket 6: 438 units\nSubmarket 7: 3616 units\nSubmarket 8: 162 units\nSubmarket 9: 878 units\nSubmarket 10: 2246 units\nSubmarket 11: 2500 units\nSubmarket 12: 657 units\nSubmarket 13: 52 units\nSubmarket 14: 3100 units\nSubmarket 15: 2010 units\nSubmarket 16: 2750 units\nSubmarket 17: 2397 units\nSubmarket 18: 60 units\nFor cluster 0\nTrain set accuracy: 0.6601636249213342\nTest set accuracy: 0.6568877551020408\nNumber of Homes: 784\nExpected #Sales: 268\nActual #Sales: 269\n\n=======\nFor cluster 1\nTrain set accuracy: 0.5973516429622364\nTest set accuracy: 0.6129353233830845\nNumber of Homes: 1005\nExpected #Sales: 400\nActual #Sales: 389\n\n=======\nFor cluster 2\nTrain set accuracy: 0.7045454545454546\nTest set accuracy: 0.5909090909090909\nNumber of Homes: 44\nExpected #Sales: 13\nActual #Sales: 18\n\n=======\nFor cluster 3\nTrain set accuracy: 0.580805794477139\nTest set accuracy: 0.5968778696051423\nNumber of Homes: 1089\nExpected #Sales: 458\nActual #Sales: 439\n\n=======\nFor cluster 4\nTrain set accuracy: 0.658357771260997\nTest set accuracy: 0.6824925816023739\nNumber of Homes: 337\nExpected #Sales: 115\nActual #Sales: 107\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6072534276868642\nTest set accuracy: 0.6202872531418312\nNumber of Homes: 1114\nExpected #Sales: 437\nActual #Sales: 423\n\n=======\nFor cluster 6\nTrain set accuracy: 0.7303754266211604\nTest set accuracy: 0.7310344827586207\nNumber of Homes: 145\nExpected #Sales: 38\nActual #Sales: 39\n\n=======\nFor cluster 7\nTrain set accuracy: 0.6424442609413707\nTest set accuracy: 0.6155778894472361\nNumber of Homes: 1194\nExpected #Sales: 427\nActual #Sales: 459\n\n=======\nFor cluster 8\nTrain set accuracy: 0.7870370370370371\nTest set accuracy: 0.7407407407407407\nNumber of Homes: 54\nExpected #Sales: 11\nActual #Sales: 14\n\n=======\nFor cluster 9\nTrain set accuracy: 0.6292517006802721\nTest set accuracy: 0.6068965517241379\nNumber of Homes: 290\nExpected #Sales: 110\nActual #Sales: 113\n\n=======\nFor cluster 10\nTrain set accuracy: 0.6549202127659575\nTest set accuracy: 0.6455525606469003\nNumber of Homes: 742\nExpected #Sales: 257\nActual #Sales: 263\n\n=======\nFor cluster 11\nTrain set accuracy: 0.6208955223880597\nTest set accuracy: 0.6327272727272727\nNumber of Homes: 825\nExpected #Sales: 313\nActual #Sales: 303\n\n=======\nFor cluster 12\nTrain set accuracy: 0.7227272727272728\nTest set accuracy: 0.6728110599078341\nNumber of Homes: 217\nExpected #Sales: 61\nActual #Sales: 71\n\n=======\nFor cluster 13\nTrain set accuracy: 0.6176470588235294\nTest set accuracy: 0.9444444444444444\nNumber of Homes: 18\nExpected #Sales: 7\nActual #Sales: 1\n\n=======\nFor cluster 14\nTrain set accuracy: 0.5753490611458835\nTest set accuracy: 0.5640273704789834\nNumber of Homes: 1023\nExpected #Sales: 432\nActual #Sales: 435\n\n=======\nFor cluster 15\nTrain set accuracy: 0.6894502228826151\nTest set accuracy: 0.6807228915662651\nNumber of Homes: 664\nExpected #Sales: 206\nActual #Sales: 212\n\n=======\nFor cluster 16\nTrain set accuracy: 0.6313789359391965\nTest set accuracy: 0.6464757709251101\nNumber of Homes: 908\nExpected #Sales: 339\nActual #Sales: 321\n\n=======\nFor cluster 17\nTrain set accuracy: 0.6398753894080997\nTest set accuracy: 0.6262626262626263\nNumber of Homes: 792\nExpected #Sales: 285\nActual #Sales: 296\n\n=======\nFor cluster 18\nTrain set accuracy: 0.6\nTest set accuracy: 0.65\nNumber of Homes: 20\nExpected #Sales: 8\nActual #Sales: 7\n\n=======\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-a4c85c07-b37c-46f5-ae12-fd6605397101",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "32dc4734",
        "execution_millis": 12,
        "execution_start": 1619565342696,
        "deepnote_cell_type": "code"
      },
      "source": "print(f'the mininum MSE score is where there are {[m for m in range(3,20,1)][np.argmin(mse_list)]} submarkets')",
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "text": "the mininum MSE score is where there are 19 submarkets\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Run on eleven submarkets",
      "metadata": {
        "tags": [],
        "cell_id": "00010-b76bbf60-f151-4e5f-b822-aadcf2e6010b",
        "deepnote_cell_type": "text-cell-h3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-5e160f9f-9bd9-4c19-b73e-dad6dab94cbe",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1403ee66",
        "execution_start": 1619565342719,
        "execution_millis": 5379,
        "deepnote_cell_type": "code"
      },
      "source": "#attempt kmeans clustering\n#unsupervised approach\n#finding the optimum value of k\n\n\nK = 11\ninit_clustering = KMeans(n_clusters=K, random_state=0).fit(X)\n\ncluster_labels = init_clustering.labels_\n\nfor k in range(K):\n    print('Submarket {}: {} units'.format(k, sum(cluster_labels == k)))\n\n#create a new df with has the clustering labels on it\nX_withlabels = X.copy()\nX_withlabels['labels'] = cluster_labels \n\n    # Fitting logistic regression to identified clusters from Kmeans\ntrain_test_dict = {}\n\n    #for loop which extracts the X & y df for each cluster\n#these will then be used to run the logistic regression \nfor i in range(K):\n    X2 = X_withlabels.loc[X_withlabels['labels'] == i]\n    X2 = X2.drop(columns = 'labels')\n    y2 = Y[X_withlabels['labels'] == i]\n    X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.33, random_state =297)\n\n    train_test_dict[f'cluster {i}'] = (X_train, X_test, y_train, y_test)\n\n#now to fit for each cluster and get final results\n\nresults_dict = {}\n\ntrain_acc_agg = 0\ntrain_size = 0\ntest_acc_agg = 0\ntest_expsales_agg = 0\ntest_sales_agg = 0\ntest_size = 0\n\ntest = np.array([])\npred = np.array([])\n\n#fit k number of logistic regressions and get results\nfor i in range(K):\n    logit_reg = LogisticRegression()\n    X_train = train_test_dict[f'cluster {i}'][0]\n    X_test = train_test_dict[f'cluster {i}'][1]\n    y_train = train_test_dict[f'cluster {i}'][2]\n    y_test = train_test_dict[f'cluster {i}'][3]\n\n    #fit the logistic regression to each cluster\n    logit_reg.fit(X_train, y_train)\n\n            #the below code is used in order to create a df containing a breakdown of metrics\n    #on a per cluster basis\n    print(f'For cluster {i}')\n    pred_k_train = logit_reg.predict_proba(X_train)\n    pred_k = logit_reg.predict_proba(X_test)\n\n    train_accuracy, test_accuracy = print_results(logit_reg)\n    exp_sales = sum(logit_reg.predict_proba(X_test)[:,1])\n    actual_sales = sum(y_test)\n    \n    print(\"Number of test Homes: {}\".format(len(y_test)))\n    print(\"Expected test #Sales: {}\".format(round(exp_sales)))\n    print(\"Actual test #Sales: {}\\n\".format(actual_sales))\n    print('=======')\n\n    AUC_score = roc_auc_score(y_test, pred_k[:,1])\n\n    results_dict[f'cluster {i}'] = [train_accuracy, test_accuracy, AUC_score, round(exp_sales),actual_sales]\n    \n    #the below code is used to find the weighted average\n    test = np.append(test,y_test)\n    pred = np.append(pred,pred_k[:,1])\n    train_size += len(y_train)\n    train_acc_agg += train_accuracy * len(y_train)\n    test_size += len(y_test)\n    test_acc_agg += test_accuracy * len(y_test)\n    test_expsales_agg += round(exp_sales)\n    test_sales_agg += actual_sales\n\n#find MSE for this k value and append to list\n#we will choose the submarket with the lowest MSE\nresults_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "text": "Submarket 0: 2826 units\nSubmarket 1: 5992 units\nSubmarket 2: 214 units\nSubmarket 3: 4857 units\nSubmarket 4: 192 units\nSubmarket 5: 3803 units\nSubmarket 6: 4034 units\nSubmarket 7: 874 units\nSubmarket 8: 5977 units\nSubmarket 9: 4098 units\nSubmarket 10: 1240 units\nFor cluster 0\nTrain set accuracy: 0.6772319070258849\nTest set accuracy: 0.6763129689174705\nNumber of test Homes: 933\nExpected test #Sales: 301\nActual test #Sales: 302\n\n=======\nFor cluster 1\nTrain set accuracy: 0.5817140009965122\nTest set accuracy: 0.5783619817997978\nNumber of test Homes: 1978\nExpected test #Sales: 827\nActual test #Sales: 834\n\n=======\nFor cluster 2\nTrain set accuracy: 0.7692307692307693\nTest set accuracy: 0.7464788732394366\nNumber of test Homes: 71\nExpected test #Sales: 16\nActual test #Sales: 18\n\n=======\nFor cluster 3\nTrain set accuracy: 0.6444376152427781\nTest set accuracy: 0.6188396756082346\nNumber of test Homes: 1603\nExpected test #Sales: 567\nActual test #Sales: 613\n\n=======\nFor cluster 4\nTrain set accuracy: 0.6328125\nTest set accuracy: 0.6875\nNumber of test Homes: 64\nExpected test #Sales: 24\nActual test #Sales: 20\n\n=======\nFor cluster 5\nTrain set accuracy: 0.6585557299843015\nTest set accuracy: 0.650996015936255\nNumber of test Homes: 1255\nExpected test #Sales: 431\nActual test #Sales: 438\n\n=======\nFor cluster 6\nTrain set accuracy: 0.6291635825314582\nTest set accuracy: 0.6336336336336337\nNumber of test Homes: 1332\nExpected test #Sales: 496\nActual test #Sales: 488\n\n=======\nFor cluster 7\nTrain set accuracy: 0.6974358974358974\nTest set accuracy: 0.7508650519031141\nNumber of test Homes: 289\nExpected test #Sales: 87\nActual test #Sales: 72\n\n=======\nFor cluster 8\nTrain set accuracy: 0.6073926073926074\nTest set accuracy: 0.5990876837303598\nNumber of test Homes: 1973\nExpected test #Sales: 774\nActual test #Sales: 791\n\n=======\nFor cluster 9\nTrain set accuracy: 0.6240437158469946\nTest set accuracy: 0.6363636363636364\nNumber of test Homes: 1353\nExpected test #Sales: 520\nActual test #Sales: 475\n\n=======\nFor cluster 10\nTrain set accuracy: 0.6819277108433734\nTest set accuracy: 0.6634146341463415\nNumber of test Homes: 410\nExpected test #Sales: 131\nActual test #Sales: 138\n\n=======\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 52,
        "source_hash": "3c58d889",
        "tags": [],
        "cell_id": "00014-86b6d84f-3766-4648-a26b-8dac054d55eb",
        "execution_start": 1619565348173,
        "deepnote_cell_type": "code"
      },
      "source": "results_df = results_df.rename(columns = {0:'train_accuracy', 1:'test_accuracy', 2:'Test_AUC', 3:'expec sales', 4:'actual sales'})\nresults_df",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "application/vnd.deepnote.dataframe.v2+json": {
              "row_count": 11,
              "column_count": 5,
              "columns": [
                {
                  "name": "train_accuracy",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 11,
                    "nan_count": 0,
                    "min": "0.5817140009965122",
                    "max": "0.7692307692307693",
                    "histogram": [
                      {
                        "bin_start": 0.5817140009965122,
                        "bin_end": 0.6004656778199379,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6004656778199379,
                        "bin_end": 0.6192173546433636,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6192173546433636,
                        "bin_end": 0.6379690314667893,
                        "count": 3
                      },
                      {
                        "bin_start": 0.6379690314667893,
                        "bin_end": 0.656720708290215,
                        "count": 1
                      },
                      {
                        "bin_start": 0.656720708290215,
                        "bin_end": 0.6754723851136407,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6754723851136407,
                        "bin_end": 0.6942240619370664,
                        "count": 2
                      },
                      {
                        "bin_start": 0.6942240619370664,
                        "bin_end": 0.7129757387604921,
                        "count": 1
                      },
                      {
                        "bin_start": 0.7129757387604921,
                        "bin_end": 0.7317274155839179,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7317274155839179,
                        "bin_end": 0.7504790924073436,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7504790924073436,
                        "bin_end": 0.7692307692307693,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "test_accuracy",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 11,
                    "nan_count": 0,
                    "min": "0.5783619817997978",
                    "max": "0.7508650519031141",
                    "histogram": [
                      {
                        "bin_start": 0.5783619817997978,
                        "bin_end": 0.5956122888101294,
                        "count": 1
                      },
                      {
                        "bin_start": 0.5956122888101294,
                        "bin_end": 0.6128625958204611,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6128625958204611,
                        "bin_end": 0.6301129028307927,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6301129028307927,
                        "bin_end": 0.6473632098411244,
                        "count": 2
                      },
                      {
                        "bin_start": 0.6473632098411244,
                        "bin_end": 0.664613516851456,
                        "count": 2
                      },
                      {
                        "bin_start": 0.664613516851456,
                        "bin_end": 0.6818638238617876,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6818638238617876,
                        "bin_end": 0.6991141308721193,
                        "count": 1
                      },
                      {
                        "bin_start": 0.6991141308721193,
                        "bin_end": 0.7163644378824509,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7163644378824509,
                        "bin_end": 0.7336147448927826,
                        "count": 0
                      },
                      {
                        "bin_start": 0.7336147448927826,
                        "bin_end": 0.7508650519031141,
                        "count": 2
                      }
                    ]
                  }
                },
                {
                  "name": "Test_AUC",
                  "dtype": "float64",
                  "stats": {
                    "unique_count": 11,
                    "nan_count": 0,
                    "min": "0.471703587522337",
                    "max": "0.5857954545454547",
                    "histogram": [
                      {
                        "bin_start": 0.471703587522337,
                        "bin_end": 0.48311277422464877,
                        "count": 2
                      },
                      {
                        "bin_start": 0.48311277422464877,
                        "bin_end": 0.49452196092696055,
                        "count": 0
                      },
                      {
                        "bin_start": 0.49452196092696055,
                        "bin_end": 0.5059311476292723,
                        "count": 1
                      },
                      {
                        "bin_start": 0.5059311476292723,
                        "bin_end": 0.5173403343315841,
                        "count": 1
                      },
                      {
                        "bin_start": 0.5173403343315841,
                        "bin_end": 0.5287495210338958,
                        "count": 0
                      },
                      {
                        "bin_start": 0.5287495210338958,
                        "bin_end": 0.5401587077362076,
                        "count": 1
                      },
                      {
                        "bin_start": 0.5401587077362076,
                        "bin_end": 0.5515678944385194,
                        "count": 3
                      },
                      {
                        "bin_start": 0.5515678944385194,
                        "bin_end": 0.5629770811408311,
                        "count": 1
                      },
                      {
                        "bin_start": 0.5629770811408311,
                        "bin_end": 0.574386267843143,
                        "count": 1
                      },
                      {
                        "bin_start": 0.574386267843143,
                        "bin_end": 0.5857954545454547,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "expec sales",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 11,
                    "nan_count": 0,
                    "min": "16",
                    "max": "827",
                    "histogram": [
                      {
                        "bin_start": 16,
                        "bin_end": 97.1,
                        "count": 3
                      },
                      {
                        "bin_start": 97.1,
                        "bin_end": 178.2,
                        "count": 1
                      },
                      {
                        "bin_start": 178.2,
                        "bin_end": 259.29999999999995,
                        "count": 0
                      },
                      {
                        "bin_start": 259.29999999999995,
                        "bin_end": 340.4,
                        "count": 1
                      },
                      {
                        "bin_start": 340.4,
                        "bin_end": 421.5,
                        "count": 0
                      },
                      {
                        "bin_start": 421.5,
                        "bin_end": 502.59999999999997,
                        "count": 2
                      },
                      {
                        "bin_start": 502.59999999999997,
                        "bin_end": 583.6999999999999,
                        "count": 2
                      },
                      {
                        "bin_start": 583.6999999999999,
                        "bin_end": 664.8,
                        "count": 0
                      },
                      {
                        "bin_start": 664.8,
                        "bin_end": 745.9,
                        "count": 0
                      },
                      {
                        "bin_start": 745.9,
                        "bin_end": 827,
                        "count": 2
                      }
                    ]
                  }
                },
                {
                  "name": "actual sales",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 11,
                    "nan_count": 0,
                    "min": "18",
                    "max": "834",
                    "histogram": [
                      {
                        "bin_start": 18,
                        "bin_end": 99.6,
                        "count": 3
                      },
                      {
                        "bin_start": 99.6,
                        "bin_end": 181.2,
                        "count": 1
                      },
                      {
                        "bin_start": 181.2,
                        "bin_end": 262.79999999999995,
                        "count": 0
                      },
                      {
                        "bin_start": 262.79999999999995,
                        "bin_end": 344.4,
                        "count": 1
                      },
                      {
                        "bin_start": 344.4,
                        "bin_end": 426,
                        "count": 0
                      },
                      {
                        "bin_start": 426,
                        "bin_end": 507.59999999999997,
                        "count": 3
                      },
                      {
                        "bin_start": 507.59999999999997,
                        "bin_end": 589.1999999999999,
                        "count": 0
                      },
                      {
                        "bin_start": 589.1999999999999,
                        "bin_end": 670.8,
                        "count": 1
                      },
                      {
                        "bin_start": 670.8,
                        "bin_end": 752.4,
                        "count": 0
                      },
                      {
                        "bin_start": 752.4,
                        "bin_end": 834,
                        "count": 2
                      }
                    ]
                  }
                },
                {
                  "name": "_deepnote_index_column",
                  "dtype": "object"
                }
              ],
              "rows_top": [
                {
                  "train_accuracy": 0.6772319070258849,
                  "test_accuracy": 0.6763129689174705,
                  "Test_AUC": 0.5166927299251687,
                  "expec sales": 301,
                  "actual sales": 302,
                  "_deepnote_index_column": "cluster 0"
                },
                {
                  "train_accuracy": 0.5817140009965122,
                  "test_accuracy": 0.5783619817997978,
                  "Test_AUC": 0.47826371769717096,
                  "expec sales": 827,
                  "actual sales": 834,
                  "_deepnote_index_column": "cluster 1"
                },
                {
                  "train_accuracy": 0.7692307692307693,
                  "test_accuracy": 0.7464788732394366,
                  "Test_AUC": 0.5461215932914046,
                  "expec sales": 16,
                  "actual sales": 18,
                  "_deepnote_index_column": "cluster 2"
                },
                {
                  "train_accuracy": 0.6444376152427781,
                  "test_accuracy": 0.6188396756082346,
                  "Test_AUC": 0.5546377313098357,
                  "expec sales": 567,
                  "actual sales": 613,
                  "_deepnote_index_column": "cluster 3"
                },
                {
                  "train_accuracy": 0.6328125,
                  "test_accuracy": 0.6875,
                  "Test_AUC": 0.5857954545454547,
                  "expec sales": 24,
                  "actual sales": 20,
                  "_deepnote_index_column": "cluster 4"
                },
                {
                  "train_accuracy": 0.6585557299843015,
                  "test_accuracy": 0.650996015936255,
                  "Test_AUC": 0.5458088116116989,
                  "expec sales": 431,
                  "actual sales": 438,
                  "_deepnote_index_column": "cluster 5"
                },
                {
                  "train_accuracy": 0.6291635825314582,
                  "test_accuracy": 0.6336336336336337,
                  "Test_AUC": 0.471703587522337,
                  "expec sales": 496,
                  "actual sales": 488,
                  "_deepnote_index_column": "cluster 6"
                },
                {
                  "train_accuracy": 0.6974358974358974,
                  "test_accuracy": 0.7508650519031141,
                  "Test_AUC": 0.5343701996927803,
                  "expec sales": 87,
                  "actual sales": 72,
                  "_deepnote_index_column": "cluster 7"
                },
                {
                  "train_accuracy": 0.6073926073926074,
                  "test_accuracy": 0.5990876837303598,
                  "Test_AUC": 0.49756407212271725,
                  "expec sales": 774,
                  "actual sales": 791,
                  "_deepnote_index_column": "cluster 8"
                },
                {
                  "train_accuracy": 0.6240437158469946,
                  "test_accuracy": 0.6363636363636364,
                  "Test_AUC": 0.570326099988011,
                  "expec sales": 520,
                  "actual sales": 475,
                  "_deepnote_index_column": "cluster 9"
                },
                {
                  "train_accuracy": 0.6819277108433734,
                  "test_accuracy": 0.6634146341463415,
                  "Test_AUC": 0.5490728900255755,
                  "expec sales": 131,
                  "actual sales": 138,
                  "_deepnote_index_column": "cluster 10"
                }
              ],
              "rows_bottom": null
            },
            "text/plain": "            train_accuracy  test_accuracy  Test_AUC  expec sales  actual sales\ncluster 0         0.677232       0.676313  0.516693          301           302\ncluster 1         0.581714       0.578362  0.478264          827           834\ncluster 2         0.769231       0.746479  0.546122           16            18\ncluster 3         0.644438       0.618840  0.554638          567           613\ncluster 4         0.632812       0.687500  0.585795           24            20\ncluster 5         0.658556       0.650996  0.545809          431           438\ncluster 6         0.629164       0.633634  0.471704          496           488\ncluster 7         0.697436       0.750865  0.534370           87            72\ncluster 8         0.607393       0.599088  0.497564          774           791\ncluster 9         0.624044       0.636364  0.570326          520           475\ncluster 10        0.681928       0.663415  0.549073          131           138",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_accuracy</th>\n      <th>test_accuracy</th>\n      <th>Test_AUC</th>\n      <th>expec sales</th>\n      <th>actual sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cluster 0</th>\n      <td>0.677232</td>\n      <td>0.676313</td>\n      <td>0.516693</td>\n      <td>301</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>cluster 1</th>\n      <td>0.581714</td>\n      <td>0.578362</td>\n      <td>0.478264</td>\n      <td>827</td>\n      <td>834</td>\n    </tr>\n    <tr>\n      <th>cluster 2</th>\n      <td>0.769231</td>\n      <td>0.746479</td>\n      <td>0.546122</td>\n      <td>16</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>cluster 3</th>\n      <td>0.644438</td>\n      <td>0.618840</td>\n      <td>0.554638</td>\n      <td>567</td>\n      <td>613</td>\n    </tr>\n    <tr>\n      <th>cluster 4</th>\n      <td>0.632812</td>\n      <td>0.687500</td>\n      <td>0.585795</td>\n      <td>24</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>cluster 5</th>\n      <td>0.658556</td>\n      <td>0.650996</td>\n      <td>0.545809</td>\n      <td>431</td>\n      <td>438</td>\n    </tr>\n    <tr>\n      <th>cluster 6</th>\n      <td>0.629164</td>\n      <td>0.633634</td>\n      <td>0.471704</td>\n      <td>496</td>\n      <td>488</td>\n    </tr>\n    <tr>\n      <th>cluster 7</th>\n      <td>0.697436</td>\n      <td>0.750865</td>\n      <td>0.534370</td>\n      <td>87</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>cluster 8</th>\n      <td>0.607393</td>\n      <td>0.599088</td>\n      <td>0.497564</td>\n      <td>774</td>\n      <td>791</td>\n    </tr>\n    <tr>\n      <th>cluster 9</th>\n      <td>0.624044</td>\n      <td>0.636364</td>\n      <td>0.570326</td>\n      <td>520</td>\n      <td>475</td>\n    </tr>\n    <tr>\n      <th>cluster 10</th>\n      <td>0.681928</td>\n      <td>0.663415</td>\n      <td>0.549073</td>\n      <td>131</td>\n      <td>138</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 13,
        "source_hash": "a237525d",
        "tags": [],
        "cell_id": "00015-31164a25-7965-405e-86a7-80e32b688b88",
        "execution_start": 1619565348221,
        "deepnote_cell_type": "code"
      },
      "source": "auc_agg = roc_auc_score(test, pred)\n\nprint('Marketwide Demand Prediction')\nprint(\"Number of Homes: {}\".format(len(Y)))\nprint(\"Training Accuracy: {:.4f}%\".format(train_acc_agg*100/train_size))\nprint(\"Testing Accuracy: {:.4f}%\".format(test_acc_agg*100/test_size))\nprint(\"AUC: {:.6f}\".format(auc_agg))\nprint(f'number of homes predicted sold {test_expsales_agg}')\nprint(f'number of homes actually sold {test_sales_agg}')",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "text": "Marketwide Demand Prediction\nNumber of Homes: 34107\nTraining Accuracy: 63.0395%\nTesting Accuracy: 62.6676%\nAUC: 0.550720\nnumber of homes predicted sold 4174\nnumber of homes actually sold 4189\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Neural network on kmeans",
      "metadata": {
        "tags": [],
        "cell_id": "00017-f567a16a-f43e-47da-8350-729cc2dea32c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3f2bd8ef",
        "execution_millis": 211817,
        "execution_start": 1619565445405,
        "cell_id": "00018-9e8441a3-ce92-4897-946c-41fbb369a2ec",
        "deepnote_cell_type": "code"
      },
      "source": "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n\nmse_list = []\n\nfor clus_num in range(3,20,1):\n    K = clus_num\n    results_dict_nn = {}\n\n    train_acc_agg_nn = 0\n    train_size_nn = 0\n    test_acc_agg_nn = 0\n    test_size_nn = 0\n\n    test_nn = np.array([])\n    pred_nn = np.array([])\n\n    for i in range(K):\n        print(f'For cluster {i}')\n        X_train = train_test_dict[f'cluster {i}'][0]\n        X_test = train_test_dict[f'cluster {i}'][1]\n        y_train = train_test_dict[f'cluster {i}'][2]\n        y_test = train_test_dict[f'cluster {i}'][3]\n\n        X_train = torch.tensor(X_train.astype(float).values, dtype=torch.float64).to(device)\n        y_train = torch.tensor(y_train, dtype=torch.int64).to(device)\n        y_train = torch.nn.functional.one_hot(y_train)\n        #fit the logistic regression to each cluster\n        net = BaselineNet(X_train.shape[1], y_train.shape[1], epochs=5000, debug=False).to(device)\n        net.feed(X_train, y_train)\n\n        #the below code is used in order to create a df containing a breakdown of metrics\n        #on a per cluster basis\n        with torch.no_grad():\n          net.eval()\n          X_test = torch.tensor(X_test.astype(float).values, dtype=torch.float64).to(device)\n          y_test = torch.tensor(y_test, dtype=torch.int64).to(device)\n          y_test = torch.nn.functional.one_hot(y_test)\n\n          y_pred = net.forward(X_test.float()) \n          labels = torch.max(y_test, 1)[1]\n          correct = 0\n          total = y_pred.shape[0]\n          _, predicted = torch.max(y_pred.data, 1)\n          correct += (predicted == labels).sum()\n          test_accuracy = 100 * correct/total\n          print('Test accuracy: {}'.format(test_accuracy))\n\n          y_pred_train = net.forward(X_train.float()) \n          labels_train = torch.max(y_train, 1)[1]\n          correct_train = 0\n          total_train = y_pred_train.shape[0]\n          _, predicted_train = torch.max(y_pred_train.data, 1)\n          correct_train += (predicted_train == labels_train).sum()\n          train_accuracy = 100 * correct_train/total_train\n          print('Train accuracy: {}'.format(train_accuracy))\n        print('=======')\n\n        y_test = y_test.cpu()\n        AUC_score = roc_auc_score(y_test.cpu(), predicted.cpu().reshape(-1,1))\n\n        results_dict_nn[f'cluster {i}'] = [train_accuracy, test_accuracy, AUC_score]\n\n        #the below code is used to find the weighted average\n        test_nn = np.append(test_nn,y_test[:,1])\n        pred_nn = np.append(pred_nn, predicted.cpu())\n        train_size_nn += len(y_train)\n        train_acc_agg_nn += train_accuracy * len(y_train)\n        test_size_nn += len(y_test)\n        test_acc_agg_nn += test_accuracy * len(y_test)\n    mse_list.append(mean_squared_error([test_expsales_agg],[test_sales_agg]))",
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "text": "For cluster 0\nTest accuracy: 32.36870193481445\nTrain accuracy: 32.27680969238281\n=======\nFor cluster 1\nTest accuracy: 57.83619689941406\nTrain accuracy: 58.17140197753906\n=======\nFor cluster 2\n",
          "output_type": "stream"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d3811ba26794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#fit the logistic regression to each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaselineNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#the below code is used in order to create a df containing a breakdown of metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/work/cs297_rex/scripts/models.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mcnt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_enter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "32dc4734",
        "execution_start": 1619565659186,
        "execution_millis": 37,
        "cell_id": "00019-d9e81a23-0502-4596-96be-01052f986cc1",
        "deepnote_cell_type": "code"
      },
      "source": "print(f'the mininum MSE score is where there are {[m for m in range(3,20,1)][np.argmin(mse_list)]} submarkets')",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "attempt to get argmin of an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d39887a5c0dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'the mininum MSE score is where there are {[m for m in range(3,20,1)][np.argmin(mse_list)]} submarkets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \"\"\"\n\u001b[0;32m-> 1269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "deepnote_to_be_reexecuted": false,
        "source_hash": "9e509d27",
        "execution_start": 1619565661635,
        "execution_millis": 16,
        "cell_id": "00020-5e66fe8c-dffb-40a4-8bc6-3761469bf4c8",
        "deepnote_cell_type": "code"
      },
      "source": "auc_agg_nn = roc_auc_score(test_nn, pred_nn)\n\nprint('Marketwide Demand Prediction')\nprint(\"Number of Homes: {}\".format(len(Y)))\nprint(\"Training Accuracy: {:.4f}%\".format(train_acc_agg_nn*100/train_size_nn))\nprint(\"Testing Accuracy: {:.4f}%\".format(test_acc_agg_nn*100/test_size_nn))\nprint(\"AUC: {:.6f}\".format(auc_agg_nn))",
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "text": "Marketwide Demand Prediction\nNumber of Homes: 34107\nTraining Accuracy: 4987.3032%\nTesting Accuracy: 4967.3652%\nAUC: 0.455176\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00015-a00e3dd8-5ca7-4bd1-b917-19175db9d692",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=1c850c61-d934-4c85-b16d-3cb283df0c84' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "d05a0dc6-7cd0-4d20-b151-cc27fed54bfc",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  }
}